{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da732db-c063-40b1-8189-b773752104a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "# with open('gemi_flash_zeroshot_no_emo.json','r') as f:\n",
    "#     data = json.load(f)\n",
    "with open('gemi_flash_zeroshot_summ.json','r') as f:\n",
    "    data = json.load(f)\n",
    "# with open('gemi_flash_zeroshot_desc.json','r') as f:\n",
    "#     data = json.load(f)\n",
    "# csv = pd.read_csv('gpt-comp-test.csv')\n",
    "#csv = pd.read_csv('gpt-sum-test.csv')\n",
    "#csv = pd.read_csv('gpt-desc-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8269d5-b3d1-4f47-a08d-4e7ce833c757",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final_data ={'idx':[],\n",
    "            'pred':[],\n",
    "            }\n",
    "df = pd.read_csv('final_data.csv')\n",
    "# for i,idx in enumerate(data['idx']):\n",
    "#     if idx!='R12ZN5OFE1SZFF':\n",
    "#         result = list(df.loc[df['ID'] == idx, 'Aspects'])\n",
    "#         final_data['aspect'].append(result[0])\n",
    "#         final_data['idx'].append(idx)\n",
    "#         final_data['pred'].append(data['pred'][i])\n",
    "for i,idx in enumerate(data['idx']):\n",
    "    #if idx!='R12ZN5OFE1SZFF':\n",
    "        result = list(df.loc[df['ID'] == idx, 'Aspects'])\n",
    "        #final_data['aspect'].append(result[0])\n",
    "        final_data['idx'].append(idx)\n",
    "        final_data['pred'].append(data['pred'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d135d6-bc0b-47fa-9965-fe46f51027fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment \n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Download necessary NLTK data (if not already downloaded)\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Initialize the VADER sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def normalize_score(score, min_val=-1, max_val=1):\n",
    "    \"\"\"\n",
    "    Normalizes a sentiment score to be between 0 and 1.\n",
    "    \"\"\"\n",
    "    return (score - min_val) / (max_val - min_val)\n",
    "\n",
    "def process_text(text):\n",
    "    \"\"\"\n",
    "    Splits the text into sentences and computes the sentiment\n",
    "    (normalized compound score) for each sentence.\n",
    "    \n",
    "    Returns:\n",
    "      - sentences: a list of sentence strings.\n",
    "      - sentence_scores: a list of normalized sentiment scores (floats) for each sentence.\n",
    "      - final_score: the sum of the sentence sentiment scores, normalized.\n",
    "    \"\"\"\n",
    "    sentences = sent_tokenize(text)\n",
    "    sentence_scores = []\n",
    "    for sentence in sentences:\n",
    "        score = analyzer.polarity_scores(sentence)['compound']\n",
    "        #normalized = normalize_score(score)\n",
    "        normalized = score\n",
    "        sentence_scores.append(normalized)\n",
    "        sentence_scores.append(normalized)\n",
    "    final_score = sum(sentence_scores) / len(sentence_scores) if sentence_scores else 0\n",
    "    return sentences, sentence_scores, final_score\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# Prepare lists to store the breakdown for each sample\n",
    "all_sentences = []       # list of lists: one list per sample's sentences\n",
    "all_sentence_scores = [] # list of lists: one list per sample's sentence scores\n",
    "final_scores = []        # list of final combined scores (one per sample)\n",
    "    \n",
    "# Process each sample (row) in the CSV\n",
    "for idx, p in enumerate(final_data['pred']):\n",
    "    text = str(p)  # Ensure the text is a string\n",
    "    sentences, scores, final_score = process_text(text)\n",
    "        \n",
    "    # Print the breakdown for this sample\n",
    "    # print(f\"Sample {idx+1}:\")\n",
    "    # for i, sentence in enumerate(sentences):\n",
    "    #     print(f\"  Sentence {i+1}: {sentence}\")\n",
    "    #     print(f\"    Normalized sentiment score: {scores[i]:.4f}\")\n",
    "    # print(f\"  Final combined normalized sentiment score: {final_score:.4f}\")\n",
    "    # print(\"-\" * 40)\n",
    "        \n",
    "    # Store the results in lists\n",
    "    all_sentences.append(sentences)\n",
    "    all_sentence_scores.append(scores)\n",
    "    final_scores.append(final_score)\n",
    "    \n",
    "# Add the results to the DataFrame as new columns\n",
    "final_data['sentences'] = all_sentences\n",
    "final_data['sentence_scores'] = all_sentence_scores\n",
    "final_data['final_sentiment'] = final_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf2e6d0-ee3f-404b-a85b-4037f9e54331",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Vader Score:', round(sum(final_scores)/len(final_scores),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a06fe1-3555-4595-8e98-88f4144f5f4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (HyperMOE)",
   "language": "python",
   "name": "hypermoe"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
